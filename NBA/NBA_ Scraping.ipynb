{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2bc17fa-12c8-46e6-97c2-4c859cda4014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "import time\n",
    "import requests\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d579ca8f-f844-480f-9256-406a5eaa7ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "standings_dir = os.path.join(data_dir, \"standings\")\n",
    "score_dir = os.path.join(data_dir, \"scores\")\n",
    "#directories where we are going store our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c42385f-f4db-4320-b39e-a533403704ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_html(url, selector, sleep=5):            #async allows to perform non-blocking In/Out operations\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()                    #check if the request was successful\n",
    "        html_content = response.text                   #if the request is successful, it retrieves the HTML content from the response\n",
    "        await asyncio.sleep(sleep)                     #asynchronously waits for the specified duration using asyncio.sleep\n",
    "\n",
    "        return html_content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "    \n",
    "        print(f\"Error occurred while fetching HTML from {url}: {e}\")\n",
    "        return None                                     #return None if there's an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6740940b-7ca7-4f7b-af20-b280a93f2ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seasons = list(range(1994,2024))                      #set the seasons range for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5eb6178-8b6d-4f90-9b3a-b93206f59cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_season(season):\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    page = requests.get(url)\n",
    "    print(page.status_code)\n",
    "\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    html_divs = soup.find_all('div', class_='filter')  \n",
    "\n",
    "    for div in html_divs:\n",
    "        soup2 = BeautifulSoup(str(div), \"html.parser\")  \n",
    "        links = soup2.find_all(\"a\")\n",
    "        hrefs = [l.get('href') for l in links]\n",
    "\n",
    "\n",
    "        standings_pages = [f\"https://www.basketball-reference.com{l}\" for l in hrefs]\n",
    "\n",
    "        \n",
    "        for url in standings_pages:\n",
    "            save_path = os.path.join(standings_dir, url.split(\"/\")[-1])\n",
    "            if os.path.exists(save_path):\n",
    "                continue\n",
    "\n",
    "            html = await get_html(url, \"#all_schedule\")\n",
    "            with open(save_path, \"w+\") as f:\n",
    "                f.write(html)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d844604-03e1-475c-84e3-0278e51dd6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for season in seasons:             #make the loop for each season\n",
    "    await scrape_season(season)    #ensuring that each scrape_season call is completed before moving on to the next one\n",
    "#200 shows that connection is good and season is scrapining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "737347b0-b6e2-48b0-80a1-4ef6c6ecc1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standings_files = os.listdir(standings_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70bcc3aa-ae82-4cd5-8427-7143c7a45cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def scrape_game(standings_files):    \n",
    "    with open(standings_files, 'r') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    links = soup.find_all('a')\n",
    "    href = [l.get('href') for l in links]\n",
    "    box_scores = [l for l in href if l and \"boxscore\" in l and \".html\" in l]\n",
    "    box_scores = [f\"https://www.basketball-reference.com{l}\" for l in box_scores]\n",
    "\n",
    "    for url in box_scores:\n",
    "        save_path = os.path.join(score_dir, url.split(\"/\")[-1])\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "\n",
    "        html = await get_html(url, \"#content\")\n",
    "        if not html:\n",
    "            continue        \n",
    "        with open(save_path, \"w+\") as f:\n",
    "            f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d15cc1-c0c3-4915-b152-cd89a03cff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "standings_files = [s for s in standings_files if \".html\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1aa9e8-47a1-484d-95b4-9bf11648b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "standings_files = [s for s in standings_files if any(str(year) in s for year in [2008, 2009, 2014, 2017, 1994, 1995])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffaefa83-f0ff-4771-92ae-a51e110d2765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in standings_files:\n",
    "    file_path = os.path.join(standings_dir, f)\n",
    "        \n",
    "    await scrape_game(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee0b0bfb-7004-4440-9a2d-464473b8036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i stopped the function above, because it's already running for 24h, so let's check how many file we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bae2fa4-a38f-43a9-8dc7-547311e06509",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dir = \"data/scores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "234a5347-d7e9-4296-a1ee-3d1665cef751",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_score = os.listdir(score_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "434a6f50-3d71-400f-b463-9110a6ee5957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13548"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(box_score)       #check amount of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c50248-1c25-459e-8d74-f30547adaa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so by next step I'll parsing data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
